# 必备数学基础

### 函数

**函数的定义**：

- y = f(x) 其中x是自变量，y是因变量。y随着x变化

**几种特性**：

奇偶性、周期性、单调性（如下图）

![1603372698983](assets/1603372698983.png)

**极限**：

- 按照一定次数排列的数：x1，x2，...，xn，其中xn叫做通项
- 对于数列｛xn｝,当n无限增大时，其通项无限接近于一个常数A，则称该数列以A为极限或称数列收敛于A。

**导数**：

- 都有对应的结果，不用死记硬背，查就行了，如(C)' = 0 或者(sin x)' = cos x



### 方向导数（引出梯度）

> 在函数定义域的内点，对某一*方向*求导得到的*导数*。
>
> 常规数学中，所有问题都有一个解。而机器学习当中，求解很难或者没有解，我们只能不断逼近这个最优解。

![1603586067346](assets/1603586067346.png)

> 蚂蚁沿着任意方向都可以活，最优的是沿着对角方向L，z是函数变化，也就是图中的φ。

![1603586587946](assets/1603586587946.png)

> 上面是三维平面的方向导数公式

![1603586750205](assets/1603586750205.png)

> 求一个方向导数具体的值



### 梯度

> 是一个向量（矢量），表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此*梯度*的方向）变化最快，变化率最大（为该*梯度*的模）。

![1603586920082](assets/1603586920082.png)

> 根据上面的梯度导数，和方向导数的区别就在多了个cosθ，θ充当梯度和方向导数之间的关系

![1603587120862](assets/1603587120862.png)

> 注意，只有θ=0，cos导数才能=1，梯度才能取得最大值，也就是那个方向。而沿着反方向就是最小值也就是梯度下降。

求一个具体值，最大梯度方向和最小梯度方向

![1603587998293](assets/1603587998293.png)

> 注：得出的经过(-1,0,2)，求解：((-1^2) + (0^2) + (-2^2)) = √5，前面都是x的平方，所以结果也需要开根号。



### 微积分

> 很多的微分积起来

如何求A面积的值

![1603589223245](assets/1603589223245.png)

以直代曲

![1603589301289](assets/1603589301289.png)

> 越小的矩形，越覆盖，求出每个矩形的面积。

![1603589430186](assets/1603589430186.png)

> 注意每个小区间的最大长度为λ，而λ无限接近于0时，那么曲边的面积我们就可以得出，当然这里的近似表达是极限，无限接近的极限。

求和

![1603589561963](assets/1603589561963.png)

> 将上面的所有矩阵求和，∫ = sum，求和的意思

**定积分**:

![1603590034899](assets/1603590034899.png)



### 矩阵和特征

**矩阵**：

> 拿到数据后，数据就长如下样子，有行有列

![1603615232363](assets/1603615232363.png)

> 左图√表示A可以到B和C，如右上图，再把√号改成0/1以存储在数据里面，就如右下图

**几种特别的矩阵**：

![1603616214041](assets/1603616214041.png)

> 上三角部分有值，和下三角部分有值

![1603616244944](assets/1603616244944.png)

> 对角阵：对角有值且可以是任意值，单位矩阵：对角有值且相同

![1603616315241](assets/1603616315241.png)

> 同型矩阵：行列相同。矩阵相等：行列相同且里面的值一样

### SVD矩阵分解

数据行列可能很大，如电商行业100万客户（行），有1万的商品（特征），用一组数据表达就是

| 客户ID   | 商品1             | 商品2 | ...  | 商品1万 |
| -------- | ----------------- | ----- | ---- | ------- |
| xxx1     | 1（表示买过一次） | 0     | ...  | 5       |
| xxx2     | 0                 | 1     | ...  | 0       |
| ...      | 5                 | 10    | ...  | 0       |
| xxx100万 | ...               | ...   | ...  | ...     |

那么来一个客户，就是直接多1万列表示，这样的数据是非常稀疏的，我们可以分解成A表100万客户，100个特征，而这100个特征对应这那B表的1万个商品，也就是一个表变成A表和B表，且两者关联。

这就需要用到SVD矩阵。



### 离散和连续型数据

![1603623698138](assets/1603623698138.png)

> 离散型是有限多个的，比如10个台阶，只可能是其中的一个台阶，一个确定的结果。
>
> 连续型则可能是任意的值，没办法确定是哪个台阶。

**离散型随机变量概率分布**

![1603624212861](assets/1603624212861.png)

**连续型随机变量概率分布**

![1603624629046](assets/1603624629046.png)

> 还有一种方法是把每个值划分在不同区间，变成离散型，但如果有新数据进来就要再划分区间导致区间越来越多。

### 简单随机抽样

抽取的样本满足两点

1. 样本X1，X2...Xn是相互独立的随机变量。
2. 样本X1，X2...Xn与总体X同分布。

![1603624871257](assets/1603624871257.png)

### 极大似然估计

> 找到最有可能的那个

![1603626327837](assets/1603626327837.png)

> 第一步构造函数；第二步取对数，对数后的值容易取且极值点还是那个位置；第三步求偏导；得到θ

![1603626465653](assets/1603626465653.png)

![1603626480659](assets/1603626480659.png)

