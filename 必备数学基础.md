# 必备数学基础

### 函数

**函数的定义**：

- y = f(x) 其中x是自变量，y是因变量。y随着x变化

**几种特性**：

奇偶性、周期性、单调性（如下图）

![1603799800751](assets/1603799800751.png)

**极限**：

- 按照一定次数排列的数：x1，x2，...，xn，其中xn叫做通项
- 对于数列｛xn｝,当n无限增大时，其通项无限接近于一个常数A，则称该数列以A为极限或称数列收敛于A。

**导数**：

- 都有对应的结果，不用死记硬背，查就行了，如(C)' = 0 或者(sin x)' = cos x



### 方向导数（引出梯度）

> 在函数定义域的内点，对某一*方向*求导得到的*导数*。
>
> 常规数学中，所有问题都有一个解。而机器学习当中，求解很难或者没有解，我们只能不断逼近这个最优解。

**问题一**：蚂蚁沿着什么方向跑路不被火烧，能活下来（二维平面）

![有个坐标轴x,y，(0,0)处着火，蚂蚁应该怎么走](assets/1603799891825.png)

> 蚂蚁沿着任意方向都可以活，最优的是沿着对角方向L，z是函数变化，也就是图中的φ。

**三维平面的方向导数公式**：

![1603799859450](assets/1603799859450.png)



**求一个方向导数具体的值**：

求函数![1603800015017](assets/1603800015017.png)在点P(1,0)处，沿着从点P(1,0)到点Q(2,-1)的方向的方向导数。

![1603800127515](assets/1603800127515.png)



所求方向导数

![1603800171837](assets/1603800171837.png)

### 梯度

> 是一个向量（矢量），表示某一函数在该点处的方向导数沿着该方向取得最大值，即函数在该点处沿着该方向（此*梯度*的方向）变化最快，变化率最大（为该*梯度*的模）。

函数：z = f(x,y)在平面域内具有连续的一阶偏导数，对于其中每个点P(x,y)都有向量![1603800802065](assets/1603800802065.png)则其称为函数点P的梯度。

![1603800856376](assets/1603800856376.png)

![1603800888757](assets/1603800888757.png)是方向L上的单位向量

![1603800922280](assets/1603800922280.png)

![1603800960729](assets/1603800960729.png)

> 根据上面的梯度导数，和方向导数的区别就在多了个*cosθ*，*θ*充当梯度和方向导数之间的关系

只有当![1603801027540](assets/1603801027540.png)才有最大值

函数在某点的梯度是一个向量，它的方向与方向导数最大值取得的方向一致。

其大小正好是最大的方向导数

![梯度图](assets/1603681846373.png)

> 注意，只有*θ*=0，*cos*导数才能=1，梯度才能取得最大值，也就是那个方向。而沿着反方向就是最小值也就是梯度下降。

**求一个具体值，最大梯度方向和最小梯度方向**：

设![1603800305729](assets/1603800305729.png)求grad u，并求在点M(0,1,-1)处方向导数的最大（小）值

![1603800371917](assets/1603800371917.png)

![1603800394319](assets/1603800394319.png)

![1603800457473](assets/1603800457473.png)

> 注：得出的结果(-1,0,2)，求解：((-1^2) + (0^2) + (-2^2)) = √5，前面都是x的平方，所以结果也需要开根号。



### 微积分

> 很多的微分积起来

如何求A面积的值

![1603589223245](assets/1603589223245.png)

**以直代曲**：

- 对于矩形，我们可以轻松求得其面积，能否用矩形代替曲线形状呢？


- 应该用多少个矩形来代替？


![四个小矩形和九个小矩形](assets/1603685656784.png)

> 越小的矩形，越覆盖，然后求每个矩形的面积。

**面积的由来**：

- 在ab之间插入若干个点，这样就得到n个小区间。
- 每个小矩形面积为：![1603801255298](assets/1603801255298.png)近似得到曲线面积![1603801287337](assets/1603801287337.png)
- 当分割无限加细，每个小区间的最大长度为λ，此时λ → 0
- 曲边面积：![1603801393606](assets/1603801393606.png)

![1603688411669](assets/1603688411669.png)

> 注意每个小区间的最大长度为λ，而λ无限接近于0时，那么曲边的面积我们就可以得出，当然这里的近似表达是极限，无限接近的极限。

**求和**：

我们需要尽可能的将每一个矩形的底边无穷小



莱布尼茨为了体现求和的感觉，把S拉长了，简写成![1603790307464](assets/1603790307464.png)

![1603765637923](assets/1603765637923.png)

> 将上面的所有矩阵求和，∫ = sum，求和的意思

**定积分**:

当![1603790249795](assets/1603790249795.png)时，总和S总数趋于确定的极限l，则称极限l为函数f(x)在曲线[a,b]上的定积分

![1603765921296](assets/1603765921296.png)



### 矩阵和特征

**矩阵**：

> 拿到数据后，数据就长如下样子，有行有列

![1603615232363](assets/1603615232363.png)

> 左图√表示A可以到B和C，如右上图，再把√号改成0/1以存储在数据里面，就如右下图

**几种特别的矩阵**：

![1603790184301](assets/1603790184301.png)

> 上三角部分有值，和下三角部分有值

![1603790200046](assets/1603790200046.png)

> 对角阵：对角有值且可以是任意值，单位矩阵：对角有值且相同

![1603790209907](assets/1603790209907.png)

> 同型矩阵：行列相同。矩阵相等：行列相同且里面的值一样

### SVD矩阵分解

数据行列可能很大，如电商行业100万客户（行），有1万的商品（特征），用一组数据表达就是

| 客户ID   | 商品1             | 商品2 | ...  | 商品1万 |
| -------- | ----------------- | ----- | ---- | ------- |
| xxx1     | 1（表示买过一次） | 0     | ...  | 5       |
| xxx2     | 0                 | 1     | ...  | 0       |
| ...      | 5                 | 10    | ...  | 0       |
| xxx100万 | ...               | ...   | ...  | ...     |

那么来一个客户，就是直接多1万列表示，这样的数据是非常稀疏的，我们可以分解成A表100万客户，100个特征，而这100个特征对应这那B表的1万个商品，也就是一个表变成A表和B表，且两者关联。

这就需要用到SVD矩阵。



### 离散和连续型数据

![1603623698138](assets/1603623698138.png)

> 离散型是有限多个的，比如10个台阶，只可能是其中的一个台阶，一个确定的结果。
>
> 连续型则可能是任意的值，没办法确定是哪个台阶。

**离散型随机变量概率分布**

- 找到离散型随机变量X的所有可能取值

- 得到离散型随机变量取这些值的概率

  ![1603767423885](assets/1603767423885.png)

  ![1603790123695](assets/1603790123695.png)为离散型随机变量的概率函数

**连续型随机变量概率分布**

- 密度：一个物体，如果问其中一个点的质量是多少？这该怎么求？

  由于这个点实在太小了，那么质量就为0了，但是其中的一大块是由

  很多个点组成的，这时我们就可以根据密度来求其质量了

- X为连续随机变量，X在任意区间(a,b]上的概率可以表示为：

  ![1603790041924](assets/1603790041924.png)其中f(x)就叫做X的概率密度函数，也可以简单叫做密度

> 还有一种方法是把每个值划分在不同区间，变成离散型，但如果有新数据进来就要再划分区间导致区间越来越多。

### 简单随机抽样

抽取的样本满足两点

1. 样本X1，X2...Xn是相互独立的随机变量。

2. 样本X1，X2...Xn与总体X同分布。

   ![1603790015180](assets/1603790015180.png)

### 极大似然估计

> 找到最有可能的那个

1. 构造似然函数：L(θ)

2. 对似然函数取对数：lnL(θ)

   > 做log后，logAB = logA + logB，加法更好求

3. 求偏导![1603801570385](assets/1603801570385.png)

4. 求解得到 θ 值

   ![1603768031523](assets/1603768031523.png)

> 第一步构造函数；第二步取对数，对数后的值容易取且极值点还是那个位置；第三步求偏导；得到θ

**求一个具体的值**：

设 X 服从参数 λ(λ>0) 的泊松分布，x1,x2,...,xn 是来自 X 的一个样本值，求λ的极大似然估计值

- 因为X的分布律为![1603802012244](assets/1603802012244.png)
- 所以 λ 的似然函数为![1603802070909](assets/1603802070909.png)
- ![1603802228693](assets/1603802228693.png)
- 令![1603802263577](assets/1603802263577.png)
- 解得 λ 的极大似然估计值为 ![1603802356318](assets/1603802356318.png)





